FROM apache/airflow:2.10.5

# Use root for installation
USER root

# Install Git, OpenJDK 17, and AWS CLI
RUN apt-get update && \
    apt-get install -y git openjdk-17-jre awscli && \
    apt-get clean

# Set JAVA_HOME for JVM (used by JPype)
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="$JAVA_HOME/bin:$PATH"

# Set Airflow home and config path
ENV AIRFLOW_HOME=/opt/airflow
ENV AIRFLOW_CONFIG=/opt/airflow/airflow.cfg

# Create necessary directories
RUN mkdir -p /opt/airflow/libs /opt/airflow/java-jars /opt/airflow/utils /opt/airflow/dags

# Copy JARs and other static resources
COPY airflow/java-jars/transformer-lib-1.0.0-SNAPSHOT.jar /opt/airflow/libs/
COPY airflow/java-jars/ /opt/airflow/java-jars/
COPY airflow/utils/ /opt/airflow/utils/
COPY airflow/templates/ /opt/airflow/templates/
COPY airflow/dags/dynamic_dag_generator.py /opt/airflow/dags/

# Copy airflow.cfg and set ownsership
COPY airflow/airflow.cfg /opt/airflow/airflow.cfg
RUN chown airflow: /opt/airflow/airflow.cfg

# Copy the custom entrypoint script and make it executable
COPY airflow/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Switch to airflow user
USER airflow

# Install Python dependencies
RUN pip install jpype1 apache-airflow-providers-mongo

# Override DAGs folder location if needed (already the default)
ENV AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags

# Expose Airflow webserver port
EXPOSE 8080

# Set the entrypoint to custom script that pulls DAGs from S3
ENTRYPOINT ["/entrypoint.sh"]

# Default command to run Airflow
CMD ["airflow", "standalone"]